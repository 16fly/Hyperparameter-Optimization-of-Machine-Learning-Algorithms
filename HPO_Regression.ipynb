{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hyperparameter Optimization (HPO) of Machine Learning Models\n",
    "L. Yang and A. Shami, \"On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice,\" Neurocomputing, 2020.\n",
    "\n",
    "### **Sample code for regression problems**  \n",
    "**Dataset used:**  \n",
    "&nbsp; Boson Housing dataset from sklearn\n",
    "\n",
    "**Machine learning algorithms used:**  \n",
    "&nbsp; Random forest (RF), support vector machine (SVM), k-nearest neighbor (KNN)\n",
    "\n",
    "**HPO algorithms used:**  \n",
    "&nbsp; Grid search, random search, hyperband, Bayesian Optimization with Gaussian Processes (BO-GP), Bayesian Optimization with Tree-structured Parzen Estimator (BO-TPE), particle swarm optimization (PSO), genetic algorithm (GA).\n",
    "\n",
    "**Performance metric:**  \n",
    "&nbsp; Mean square error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Boston Housing dataset\n",
    "\n",
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = datasets.load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'filename': 'C:\\\\Users\\\\lyang339\\\\AppData\\\\Roaming\\\\Python\\\\Python35\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv',\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Machine Learning models: Regressors with Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:29.596121527190764\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "clf = RandomForestRegressor()\n",
    "clf.fit(X,y)\n",
    "scores = cross_val_score(clf, X, y, cv=3,scoring='neg_mean_squared_error')\n",
    "print(\"MSE:\"+ str(-scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:77.42951812579331\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "clf = SVR(gamma='scale')\n",
    "clf.fit(X,y)\n",
    "scores = cross_val_score(clf, X, y, cv=3,scoring='neg_mean_squared_error')\n",
    "print(\"MSE:\"+ str(-scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:81.48773186343571\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "clf = KNeighborsRegressor()\n",
    "clf.fit(X,y)\n",
    "scores = cross_val_score(clf, X, y, cv=3,scoring='neg_mean_squared_error')\n",
    "print(\"MSE:\"+ str(-scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Algorithm 1: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'n_estimators': 20}\n",
      "MSE:29.02394449507633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_params = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    #'max_features': ['sqrt',0.5],\n",
    "    'max_depth': [15,20,30,50],\n",
    "    #'min_samples_leaf': [1,2,4,8],\n",
    "    #\"bootstrap\":[True,False],\n",
    "    #\"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "grid = GridSearchCV(clf, rf_params, cv=3, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(\"MSE:\"+ str(-grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'poly', 'epsilon': 0.01, 'C': 100}\n",
      "MSE:67.07483887754718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_params = {\n",
    "    'C': [1,10, 100],\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    \"epsilon\":[0.01,0.1,1]\n",
    "}\n",
    "clf = SVR(gamma='scale')\n",
    "grid = GridSearchCV(clf, rf_params, cv=3, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(\"MSE:\"+ str(-grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5}\n",
      "MSE:81.52933517786562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_params = {\n",
    "    'n_neighbors': [2, 3, 5,7,10]\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "grid = GridSearchCV(clf, rf_params, cv=3, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(\"MSE:\"+ str(-grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Algorithm 2: Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 49, 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 90, 'max_features': 7}\n",
      "MSE:26.825166966741307\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_params = {\n",
    "    'n_estimators': sp_randint(10,100),\n",
    "    \"max_features\":sp_randint(1,13),\n",
    "    'max_depth': sp_randint(5,50),\n",
    "    \"min_samples_split\":sp_randint(2,11),\n",
    "    \"min_samples_leaf\":sp_randint(1,11),\n",
    "    #\"criterion\":['gini','entropy']\n",
    "}\n",
    "n_iter_search=20\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'poly', 'epsilon': 0.49678099309788193, 'C': 27.417074148575495}\n",
      "MSE:60.03157881614154\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_params = {\n",
    "    'C': stats.uniform(0,50),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    \"epsilon\":stats.uniform(0,1)\n",
    "}\n",
    "n_iter_search=20\n",
    "clf = SVR(gamma='scale')\n",
    "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13}\n",
      "MSE:80.7723025469514\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_params = {\n",
    "    'n_neighbors': range(1,20),\n",
    "}\n",
    "n_iter_search=10\n",
    "clf = KNeighborsRegressor()\n",
    "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Algorithm 3: Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 45, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 33, 'max_features': 5}\n",
      "MSE:26.17217675246202\n"
     ]
    }
   ],
   "source": [
    "from hyperband import HyperbandSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "rf_params = {\n",
    "    'n_estimators': sp_randint(10,100),\n",
    "    \"max_features\":sp_randint(1,13),\n",
    "    'max_depth': sp_randint(5,50),\n",
    "    \"min_samples_split\":sp_randint(2,11),\n",
    "    \"min_samples_leaf\":sp_randint(1,11),\n",
    "    #\"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=10,max_iter=100,scoring='neg_mean_squared_error')\n",
    "hyper.fit(X, y)\n",
    "print(hyper.best_params_)\n",
    "print(\"MSE:\"+ str(-hyper.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'poly', 'epsilon': 0.4490042156616516, 'C': 10}\n",
      "MSE:70.78132735518886\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "rf_params = {\n",
    "    'C': stats.uniform(0,50),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    \"epsilon\":stats.uniform(0,1)\n",
    "}\n",
    "clf = SVR(gamma='scale')\n",
    "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=1,max_iter=10,scoring='neg_mean_squared_error',resource_param='C')\n",
    "hyper.fit(X, y)\n",
    "print(hyper.best_params_)\n",
    "print(\"MSE:\"+ str(-hyper.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 6}\n",
      "MSE:80.87024044795783\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "rf_params = {\n",
    "    'n_neighbors': range(1,20),\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=1,max_iter=20,scoring='neg_mean_squared_error',resource_param='n_neighbors')\n",
    "hyper.fit(X, y)\n",
    "print(hyper.best_params_)\n",
    "print(\"MSE:\"+ str(-hyper.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Algorithm 4: BO-GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using skopt.BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'max_features': 9}\n",
      "MSE:27.054063120553348\n"
     ]
    }
   ],
   "source": [
    "from skopt import Optimizer\n",
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "rf_params = {\n",
    "    'n_estimators': Integer(10,100),\n",
    "    \"max_features\":Integer(1,13),\n",
    "    'max_depth': Integer(5,50),\n",
    "    \"min_samples_split\":Integer(2,11),\n",
    "    \"min_samples_leaf\":Integer(1,11),\n",
    "    #\"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "bclf = Bayes.best_estimator_\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'poly', 'epsilon': 0.16781739810509447, 'C': 43.14510166511289}\n",
      "MSE:59.52440851660976\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "rf_params = {\n",
    "    'C': Real(0,50),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    'epsilon': Real(0,1)\n",
    "}\n",
    "clf = SVR(gamma='scale')\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13}\n",
      "MSE:80.7723025469514\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "rf_params = {\n",
    "    'n_neighbors': Integer(1,20),\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=10, scoring='neg_mean_squared_error')\n",
    "Bayes.fit(X, y)\n",
    "print(Bayes.best_params_)\n",
    "print(\"MSE:\"+ str(-Bayes.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using skopt.gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:26.2711\n",
      "[18, 14, 6, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor()\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "space  = [Integer(10, 100, name='n_estimators'),\n",
    "            Integer(5, 50, name='max_depth'),\n",
    "          Integer(1, 13, name='max_features'),\n",
    "          Integer(2, 11, name='min_samples_split'),\n",
    "          Integer(1, 11, name='min_samples_leaf'),\n",
    "         #Categorical(['gini', 'entropy'], name='criterion'),\n",
    "         ]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "print(\"MSE:%.4f\" % res_gp.fun)\n",
    "print(res_gp.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:61.2510\n",
      "[37.93078121611787, 'poly', 0.47360041934665753]\n"
     ]
    }
   ],
   "source": [
    "reg = SVR(gamma='scale')\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "space  = [Real(0, 50, name='C'),\n",
    "          Categorical(['poly','rbf','sigmoid'], name='kernel'),\n",
    "          Real(0, 1, name='epsilon'),\n",
    "         ]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "print(\"MSE:%.4f\" % res_gp.fun)\n",
    "print(res_gp.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:80.7412\n",
      "[13]\n"
     ]
    }
   ],
   "source": [
    "reg = KNeighborsRegressor()\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "space  = [Integer(1, 20, name='n_neighbors')]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=10, random_state=0)\n",
    "print(\"MSE:%.4f\" % res_gp.fun)\n",
    "print(res_gp.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Algorithm 5: BO-TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 20/20 [00:01<00:00, 13.61it/s, best loss: 26.857722814717487]\n",
      "Random Forest: Hyperopt estimated optimum {'max_depth': 50.0, 'min_samples_leaf': 3.0, 'min_samples_split': 7.0, 'max_features': 5.0, 'criterion': 0, 'n_estimators': 82.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']), \n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'max_features': int(params['max_features']),\n",
    "        \"min_samples_split\":int(params['min_samples_split']),\n",
    "        \"min_samples_leaf\":int(params['min_samples_leaf']),\n",
    "        #\"criterion\":str(params['criterion'])\n",
    "    }\n",
    "    clf = RandomForestRegressor( **params)\n",
    "    score = -np.mean(cross_val_score(clf, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    #print(\"ROC-AUC {:.3f} params {}\".format(score, params))\n",
    "\n",
    "    return {'loss':score, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 100, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
    "    \"max_features\":hp.quniform('max_features', 1, 13, 1),\n",
    "    \"min_samples_split\":hp.quniform('min_samples_split',2,11,1),\n",
    "    \"min_samples_leaf\":hp.quniform('min_samples_leaf',1,11,1),\n",
    "    \"criterion\":hp.choice('criterion',['gini','entropy'])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.96902491065731\n",
      "48393.901625625724\n",
      "70.84123583621884\n",
      "77.22373372727031\n",
      "1921.583414860842\n",
      "62.76781604366425\n",
      "65.95203354662758\n",
      "62.127139094608374\n",
      "78.11921987086193\n",
      "63.75742229784455\n",
      "82.73068113742441\n",
      "11511.386775697205\n",
      "12491.8779074914\n",
      "8438.521222468902\n",
      "81.28298963881998\n",
      "60.803371026183214\n",
      "64.85414012079134\n",
      "74.65877567726007\n",
      "82.64907968740728\n",
      "70.32108009755741\n",
      "100%|███████████████████████████████████████████████████| 20/20 [00:00<00:00, 63.23it/s, best loss: 60.803371026183214]\n",
      "Random Forest: Hyperopt estimated optimum {'kernel': 0, 'epsilon': 0.3306178089802077, 'C': 23.418083354013188}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'C': abs(float(params['C'])), \n",
    "        \"kernel\":str(params['kernel']),\n",
    "        'epsilon': abs(float(params['epsilon'])),\n",
    "    }\n",
    "    clf = SVR(gamma='scale', **params)\n",
    "    score = -np.mean(cross_val_score(clf, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    #print(\"ROC-AUC {:.3f} params {}\".format(score, params))\n",
    "    print(score)\n",
    "    return {'loss':score, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'C': hp.normal('C', 0, 50),\n",
    "    \"kernel\":hp.choice('kernel',['poly','rbf','sigmoid']),\n",
    "    'epsilon': hp.normal('epsilon', 0, 1),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 147.17it/s, best loss: 80.83005201647829]\n",
      "Random Forest: Hyperopt estimated optimum {'n_neighbors': 6.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_neighbors': abs(int(params['n_neighbors']))\n",
    "    }\n",
    "    clf = KNeighborsRegressor( **params)\n",
    "    score = -np.mean(cross_val_score(clf, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    #print(\"ROC-AUC {:.3f} params {}\".format(score, params))\n",
    "\n",
    "    return {'loss':score, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'n_neighbors': hp.quniform('n_neighbors', 1, 20, 1),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Algorithm 6: PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 37.745028056718674, 'min_samples_leaf': 1.2694935979785371, 'min_samples_split': 6.3674769629093, 'n_estimators': 97.73792799268917, 'max_features': 6.383593749999999}\n",
      "MSE:26.072547695737644\n"
     ]
    }
   ],
   "source": [
    "import optunity\n",
    "import optunity.metrics\n",
    "search = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_features': [1, 13],\n",
    "    'max_depth': [5,50],\n",
    "    \"min_samples_split\":[2,11],\n",
    "    \"min_samples_leaf\":[1,11],\n",
    "         }\n",
    "@optunity.cross_validated(x=X, y=y, num_folds=3)\n",
    "def performance(x_train, y_train, x_test, y_test,n_estimators=None, max_features=None,max_depth=None,min_samples_split=None,min_samples_leaf=None):\n",
    "    # fit the model\n",
    "    model = RandomForestRegressor(n_estimators=int(n_estimators),\n",
    "                                   max_features=int(max_features),\n",
    "                                   max_depth=int(max_depth),\n",
    "                                   min_samples_split=int(min_samples_split),\n",
    "                                   min_samples_leaf=int(min_samples_leaf),\n",
    "                                  )\n",
    "    #predictions = model.predict(x_test)\n",
    "    scores=-np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    #return optunity.metrics.roc_auc(y_test, predictions, positive=True)\n",
    "    return scores#optunity.metrics.accuracy(y_test, predictions)\n",
    "\n",
    "optimal_configuration, info, _ = optunity.minimize(performance,\n",
    "                                                  solver_name='particle swarm',\n",
    "                                                  num_evals=20,\n",
    "                                                   **search\n",
    "                                                  )\n",
    "print(optimal_configuration)\n",
    "print(\"MSE:\"+ str(info.optimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 0.4658203125, 'epsilon': 0.4736328125, 'C': 25.341796875}\n",
      "MSE:60.25879498950017\n"
     ]
    }
   ],
   "source": [
    "search = {\n",
    "    'C': (0,50),\n",
    "    'kernel':[0,3],\n",
    "    'epsilon': (0, 1)\n",
    "         }\n",
    "@optunity.cross_validated(x=X, y=y, num_folds=3)\n",
    "def performance(x_train, y_train, x_test, y_test,C=None,kernel=None,epsilon=None):\n",
    "    # fit the model\n",
    "    if kernel<1:\n",
    "        ke='poly'\n",
    "    elif kernel<2:\n",
    "        ke='rbf'\n",
    "    else:\n",
    "        ke='sigmoid'\n",
    "    model = SVR(C=float(C),\n",
    "                kernel=ke,\n",
    "                gamma='scale',\n",
    "                epsilon=float(epsilon)\n",
    "                                  )\n",
    "    #predictions = model.predict(x_test)\n",
    "    scores=-np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    #return optunity.metrics.roc_auc(y_test, predictions, positive=True)\n",
    "    return scores#optunity.metrics.accuracy(y_test, predictions)\n",
    "\n",
    "optimal_configuration, info, _ = optunity.minimize(performance,\n",
    "                                                  solver_name='particle swarm',\n",
    "                                                  num_evals=20,\n",
    "                                                   **search\n",
    "                                                  )\n",
    "print(optimal_configuration)\n",
    "print(\"MSE:\"+ str(info.optimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13.84912109375}\n",
      "MSE:80.74121499347262\n"
     ]
    }
   ],
   "source": [
    "search = {\n",
    "    'n_neighbors': [1, 20],\n",
    "         }\n",
    "@optunity.cross_validated(x=X, y=y, num_folds=3)\n",
    "def performance(x_train, y_train, x_test, y_test,n_neighbors=None):\n",
    "    # fit the model\n",
    "    model = KNeighborsRegressor(n_neighbors=int(n_neighbors),\n",
    "                                  )\n",
    "    #predictions = model.predict(x_test)\n",
    "    scores=-np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    #return optunity.metrics.roc_auc(y_test, predictions, positive=True)\n",
    "    return scores#optunity.metrics.accuracy(y_test, predictions)\n",
    "\n",
    "optimal_configuration, info, _ = optunity.minimize(performance,\n",
    "                                                  solver_name='particle swarm',\n",
    "                                                  num_evals=10,\n",
    "                                                   **search\n",
    "                                                  )\n",
    "print(optimal_configuration)\n",
    "print(\"MSE:\"+ str(info.optimum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HPO Algorithm 7: Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 1, 1, 1, 1] and maxint [44, 9, 8, 11, 89] detected\n",
      "--- Evolve in 4374000 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin    \tmax     \tstd    \n",
      "0  \t10    \t-29.5802\t-44.533\t-25.5803\t5.11814\n",
      "1  \t5     \t-26.9872\t-28.5839\t-25.5803\t1.14967\n",
      "2  \t5     \t-26.0642\t-26.5163\t-25.5803\t0.270993\n",
      "3  \t3     \t-25.9576\t-27.1058\t-25.5803\t0.465954\n",
      "4  \t7     \t-25.7154\t-26.5163\t-25.5803\t0.294316\n",
      "5  \t7     \t-25.5803\t-25.5803\t-25.5803\t3.55271e-15\n",
      "Best individual is: {'max_depth': 29, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 12, 'max_features': 8}\n",
      "with fitness: -25.58028227797807\n",
      "{'max_depth': 29, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 12, 'max_features': 8}\n",
      "MSE:-25.58028227797807\n"
     ]
    }
   ],
   "source": [
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from random import randrange as sp_randrange\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': range(10,100),\n",
    "    \"max_features\":range(1,13),\n",
    "    'max_depth': range(5,50),\n",
    "    \"min_samples_split\":range(2,11),\n",
    "    \"min_samples_leaf\":range(1,11),\n",
    "    #Categorical(name='criterion', categories=['gini','entropy'])#\n",
    "    #\"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
    "                                   params=rf_params,\n",
    "                                   scoring=\"neg_mean_squared_error\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=10,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=1)\n",
    "ga1.fit(X, y)\n",
    "print(ga1.best_params_)\n",
    "print(\"MSE:\"+ str(ga1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 2, 2] and maxint [2, 99, 999] detected\n",
      "--- Evolve in 300000 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd    \n",
      "0  \t10    \t-791.408\t-4580.37\t-60.3024\t1407.48\n",
      "1  \t7     \t-437.988\t-3673.51\t-60.3024\t1078.66\n",
      "2  \t6     \t-70.1584\t-80.5238\t-60.3024\t6.80748\n",
      "3  \t7     \t-67.2654\t-79.4701\t-60.3024\t7.20768\n",
      "4  \t5     \t-61.7897\t-69.2764\t-60.3024\t2.75386\n",
      "5  \t8     \t-60.3024\t-60.3024\t-60.3024\t0      \n",
      "Best individual is: {'kernel': 'poly', 'epsilon': 0.34123803949334774, 'C': 25.638198236692972}\n",
      "with fitness: -60.30244732642168\n",
      "{'kernel': 'poly', 'epsilon': 0.34123803949334774, 'C': 25.638198236692972}\n",
      "MSE:-60.30244732642168\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'C': np.random.uniform(0,50,1000),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    'epsilon': np.random.uniform(0,1,100),\n",
    "}\n",
    "clf = SVR(gamma='scale')\n",
    "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
    "                                   params=rf_params,\n",
    "                                   scoring=\"neg_mean_squared_error\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=10,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=1)\n",
    "ga1.fit(X, y)\n",
    "print(ga1.best_params_)\n",
    "print(\"MSE:\"+ str(ga1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1] and maxint [18] detected\n",
      "--- Evolve in 19 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd     \n",
      "0  \t10    \t-82.4511\t-83.3224\t-80.8702\t0.775591\n",
      "1  \t3     \t-81.8812\t-82.9839\t-80.8702\t0.718567\n",
      "2  \t6     \t-81.1339\t-81.5293\t-80.8702\t0.322889\n",
      "3  \t9     \t-81.1776\t-83.2849\t-80.8702\t0.729407\n",
      "4  \t7     \t-80.8702\t-80.8702\t-80.8702\t0       \n",
      "5  \t7     \t-80.9662\t-81.8295\t-80.8702\t0.287764\n",
      "Best individual is: {'n_neighbors': 6}\n",
      "with fitness: -80.87024044795783\n",
      "{'n_neighbors': 6}\n",
      "MSE:-80.87024044795783\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_neighbors': range(1,20),\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
    "                                   params=rf_params,\n",
    "                                   scoring=\"neg_mean_squared_error\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=10,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=1)\n",
    "ga1.fit(X, y)\n",
    "print(ga1.best_params_)\n",
    "print(\"MSE:\"+ str(ga1.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t-27.250793005044518\tRandomForestRegressor(input_matrix, RandomForestRegressor__max_depth=78, RandomForestRegressor__max_features=5, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=168)\n",
      "-2\t-25.332016721242965\tRandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__max_depth=62, RandomForestRegressor__max_features=4, RandomForestRegressor__min_samples_leaf=5, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=34), RandomForestRegressor__max_depth=78, RandomForestRegressor__max_features=5, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=168)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t-27.250793005044518\tRandomForestRegressor(input_matrix, RandomForestRegressor__max_depth=78, RandomForestRegressor__max_features=5, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=168)\n",
      "-2\t-25.332016721242965\tRandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__max_depth=62, RandomForestRegressor__max_features=4, RandomForestRegressor__min_samples_leaf=5, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=34), RandomForestRegressor__max_depth=78, RandomForestRegressor__max_features=5, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=168)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t-27.250793005044518\tRandomForestRegressor(input_matrix, RandomForestRegressor__max_depth=78, RandomForestRegressor__max_features=5, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=168)\n",
      "-2\t-24.584400304272155\tRandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__max_depth=38, RandomForestRegressor__max_features=5, RandomForestRegressor__min_samples_leaf=7, RandomForestRegressor__min_samples_split=2, RandomForestRegressor__n_estimators=45), RandomForestRegressor__max_depth=81, RandomForestRegressor__max_features=5, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=7, RandomForestRegressor__n_estimators=103)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict={'sklearn.ensemble.RandomForestRegressor': {'max_depth': range(10, 100), 'min_samples_leaf': range(1, 11), 'min_samples_split': range(2, 11), 'max_features': range(1, 13), 'n_estimators': range(20, 200)}},\n",
       "       crossover_rate=0.1, cv=3, disable_update_check=False, early_stop=5,\n",
       "       generations=3, max_eval_time_mins=5, max_time_mins=None,\n",
       "       memory=None, mutation_rate=0.9, n_jobs=1, offspring_size=5,\n",
       "       periodic_checkpoint_folder=None, population_size=10,\n",
       "       random_state=None, scoring='neg_mean_squared_error', subsample=1.0,\n",
       "       template=None, use_dask=False, verbosity=3, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': range(20,200),\n",
    "    \"max_features\":range(1,13),\n",
    "    'max_depth': range(10,100),\n",
    "    \"min_samples_split\":range(2,11),\n",
    "    \"min_samples_leaf\":range(1,11),\n",
    "    #\"criterion\":['gini','entropy']\n",
    "             }\n",
    "               \n",
    "ga2 = TPOTRegressor(generations= 3, population_size= 10, offspring_size= 5,\n",
    "                                 verbosity= 3, early_stop= 5,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.ensemble.RandomForestRegressor': parameters}, \n",
    "                                 cv = 3, scoring = 'neg_mean_squared_error')\n",
    "ga2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t-76.22342756605103\tSVR(CombineDFs(input_matrix, input_matrix), SVR__C=9.66289149097888, SVR__epsilon=0.6491076078954555, SVR__gamma=scale, SVR__kernel=rbf)\n",
      "-2\t-61.22653072468754\tSVR(SVR(CombineDFs(input_matrix, input_matrix), SVR__C=2.988848947755768, SVR__epsilon=0.31470079088508107, SVR__gamma=scale, SVR__kernel=poly), SVR__C=49.38466344757709, SVR__epsilon=0.9554593389709706, SVR__gamma=scale, SVR__kernel=poly)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t-73.46312983258913\tSVR(input_matrix, SVR__C=9.66289149097888, SVR__epsilon=0.6491076078954555, SVR__gamma=scale, SVR__kernel=poly)\n",
      "-2\t-61.22653072468754\tSVR(SVR(CombineDFs(input_matrix, input_matrix), SVR__C=2.988848947755768, SVR__epsilon=0.31470079088508107, SVR__gamma=scale, SVR__kernel=poly), SVR__C=49.38466344757709, SVR__epsilon=0.9554593389709706, SVR__gamma=scale, SVR__kernel=poly)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t-59.46539136594907\tSVR(input_matrix, SVR__C=40.42400106501475, SVR__epsilon=0.09227083238549583, SVR__gamma=scale, SVR__kernel=poly)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict={'sklearn.svm.SVR': {'kernel': ['poly', 'rbf', 'sigmoid'], 'gamma': ['scale'], 'epsilon': array([0.25137, 0.0217 , ..., 0.7522 , 0.4685 ]), 'C': array([40.05907, 22.18248, ..., 33.62995,  2.73409])}},\n",
       "       crossover_rate=0.1, cv=3, disable_update_check=False, early_stop=5,\n",
       "       generations=3, max_eval_time_mins=5, max_time_mins=None,\n",
       "       memory=None, mutation_rate=0.9, n_jobs=1, offspring_size=5,\n",
       "       periodic_checkpoint_folder=None, population_size=10,\n",
       "       random_state=None, scoring='neg_mean_squared_error', subsample=1.0,\n",
       "       template=None, use_dask=False, verbosity=3, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=time.time()\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "parameters = {\n",
    "    'C': np.random.uniform(0,50,1000),\n",
    "    \"kernel\":['poly','rbf','sigmoid'],\n",
    "    'epsilon': np.random.uniform(0,1,100),\n",
    "    'gamma': ['scale']\n",
    "             }\n",
    "               \n",
    "ga2 = TPOTRegressor(generations= 3, population_size= 10, offspring_size= 5,\n",
    "                                 verbosity= 3, early_stop= 5,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.svm.SVR': parameters}, \n",
    "                                 cv = 3, scoring = 'neg_mean_squared_error')\n",
    "ga2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t-80.83005201647829\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=6)\n",
      "\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t-80.83005201647829\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=6)\n",
      "\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t-80.83005201647829\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=6)\n",
      "\n",
      "\n",
      "The optimized pipeline was not improved after evaluating 5 more generations. Will end the optimization process.\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict={'sklearn.neighbors.KNeighborsRegressor': {'n_neighbors': range(1, 20)}},\n",
       "       crossover_rate=0.1, cv=3, disable_update_check=False, early_stop=5,\n",
       "       generations=3, max_eval_time_mins=5, max_time_mins=None,\n",
       "       memory=None, mutation_rate=0.9, n_jobs=1, offspring_size=5,\n",
       "       periodic_checkpoint_folder=None, population_size=10,\n",
       "       random_state=None, scoring='neg_mean_squared_error', subsample=1.0,\n",
       "       template=None, use_dask=False, verbosity=3, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=time.time()\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "parameters = {\n",
    "    'n_neighbors': range(1,20),\n",
    "             }\n",
    "               \n",
    "ga2 = TPOTRegressor(generations= 3, population_size= 10, offspring_size= 5,\n",
    "                                 verbosity= 3, early_stop= 5,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.neighbors.KNeighborsRegressor': parameters}, \n",
    "                                 cv = 3, scoring = 'neg_mean_squared_error')\n",
    "ga2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
